{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba65615-6ebc-4246-8474-0725de58041c",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# 0. Setup"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "collapsed": false
   },
   "source": "# Import packages\nimport streamlit as st\nimport pandas as pd\nimport plotly.express as px\nfrom snowflake.snowpark.context import get_active_session\n\n# Get Snowflake session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e91e05-8bdb-4b65-9226-3371ac5f4310",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "# 1. Filters"
  },
  {
   "cell_type": "code",
   "id": "c8e27119-eedb-4701-a086-ad8083cb842f",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Create filters\nfilter1, filter2, filter3 = st.columns(3)\n\n## Database\nwith filter1:\n    selected_db = st.text_input(\n        label = 'Insert Database:',\n        value = 'FROSTBYTE_TASTY_BYTES'\n    )\n\n## Schema\nwith filter2:\n    selected_schema = st.text_input(\n        label= 'Insert Schema:',\n        value = 'RAW_POS'\n    )\n\n## Table\nwith filter3:\n    selected_tb = st.text_input(\n        label = 'Insert Table:',\n        value = 'TRUCK'\n    )",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "85e53260-1c8b-4735-8f90-de20e5a46268",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "# 2. Data Qaulity Summary"
  },
  {
   "cell_type": "code",
   "id": "cfaebbcc-4ab3-4577-b55e-b91883f3b04d",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Query the unique and duplicate count view\nif selected_db and selected_schema and selected_tb:\n    col_names_query = '''\n        SELECT COLUMN_NAME \n        FROM {0}.INFORMATION_SCHEMA.COLUMNS \n        WHERE TABLE_CATALOG = '{0}' \n        AND TABLE_SCHEMA = '{1}' \n        AND TABLE_NAME = '{2}'\n    '''.format(selected_db, selected_schema, selected_tb)\n    \n    df_col_names = session.sql(col_names_query).to_pandas()\n    col_names = df_col_names['COLUMN_NAME'].tolist()\n    \n    # Create query to check for duplicates based on concatenated columns\n    concat_cols = \" || \".join(col_names)\n    \n    uni_dup_cnt_select_query = '''\n        SELECT\n          COUNT(DISTINCT {0}) AS UNIQUE_COUNT,\n          COUNT(*) - COUNT(DISTINCT {0}) AS DUPLICATE_COUNT\n        FROM {1}.{2}.{3}\n    '''.format(concat_cols, selected_db, selected_schema, selected_tb)\nelse:\n    uni_dup_cnt_select_query = '''\n        SELECT\n          0 AS UNIQUE_COUNT,\n          0 AS DUPLICATE_COUNT\n    '''\n\n# Convert to DataFrame\ndf_uni_dup_cnt = session.sql(uni_dup_cnt_select_query).to_pandas()\n\n# Create data quality summary visual\nuni_cnt, dup_cnt = st.columns(2)\n\n## Total cost in USD\nwith uni_cnt:\n    st.metric(\n        label = 'No. of Unqiue Records:',\n        value = df_uni_dup_cnt['UNIQUE_COUNT'][0]\n    )\n    \n## Total cost in credits\nwith dup_cnt:\n    st.metric(\n        label = 'No. of Duplicate Records:',\n        value = df_uni_dup_cnt['DUPLICATE_COUNT'][0]\n    )\n\n# Query to get duplicated records\nif selected_db and selected_schema and selected_tb:\n    dup_records_query = '''\n        SELECT *\n        FROM {0}.{1}.{2}\n        QUALIFY ROW_NUMBER() OVER(PARTITION BY {3} ORDER BY {3}) > 1\n    '''.format(selected_db, selected_schema, selected_tb, concat_cols)\n\n    df_dup_records = session.sql(dup_records_query).to_pandas()\n\n    # Display duplicated records if any\n    if not df_dup_records.empty:\n        st.dataframe(df_dup_records.sort_values(by = col_names), use_container_width = True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0bcee9b1-2144-43c0-b3b7-939559fd74f1",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "# 3. Load History"
  },
  {
   "cell_type": "code",
   "id": "e142357f-030b-4cf9-896f-a820b4400cf3",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "# Successful load history query\nif selected_db and selected_schema and selected_tb:\n    load_hist_success_query ='''\n        SELECT \n            CATALOG_ID,\n            CATALOG_NAME,\n            SCHEMA_ID,\n            SCHEMA_NAME,\n            TABLE_ID,\n            TABLE_NAME,\n            FILE_NAME,\n            TO_CHAR(LAST_LOAD_TIME, 'YYYY-MM-DD') AS LAST_LOAD_TIME,\n            STATUS,\n            ROW_COUNT,\n            ROW_PARSED\n        FROM SNOWFLAKE.ACCOUNT_USAGE.LOAD_HISTORY\n        WHERE CATALOG_NAME = '{}' \n        AND SCHEMA_NAME = '{}'\n        AND TABLE_NAME = '{}'\n        AND STATUS = 'LOADED'\n        ORDER BY LAST_LOAD_TIME ASC\n    '''.format(\n        selected_db,\n        selected_schema,\n        selected_tb\n    )\nelse:\n    load_hist_success_query ='''\n        SELECT \n            NULL AS CATALOG_ID,\n            NULL AS CATALOG_NAME,\n            NULL AS SCHEMA_ID,\n            NULL AS SCHEMA_NAME,\n            NULL AS TABLE_ID,\n            NULL AS TABLE_NAME,\n            NULL AS FILE_NAME,\n            NULL AS LAST_LOAD_TIME,\n            NULL AS STATUS,\n            0 AS ROW_COUNT,\n            0 AS ROW_PARSED\n    '''\n\n# Convert to DataFrame\ndf_load_hist_success = session.sql(load_hist_success_query).to_pandas()\n\n# Create a Plotly bar chart\nfig_load_hist_success = px.bar(df_load_hist_success, x = 'LAST_LOAD_TIME', y = 'ROW_PARSED', \n             labels = {'LAST_LOAD_TIME': 'Load Time', 'ROW_PARSED': 'No. of Rows Loaded'},\n             title = 'Successful Load History')\n\nfig_load_hist_success.update_layout(\n    xaxis_title = '',\n    yaxis_title = 'No. of Rows Loaded',\n    bargap = 0.2,\n    width = 800,\n    height = 400,\n    title = {\n        'text': 'Successful Load History',\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'\n    }\n)\n\nfig_load_hist_success.update_xaxes(\n    dtick = \"D1\",\n    tickformat = '%Y-%m-%d'\n)\n\n# Display the Plotly chart in Streamlit\nst.plotly_chart(fig_load_hist_success, use_container_width = True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4fd1bcc1-5324-4375-b920-48cfdebb6d11",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "# All load history query\nif selected_db and selected_schema and selected_tb:\n    load_hist_all_query ='''\n        SELECT \n            CATALOG_ID,\n            CATALOG_NAME,\n            SCHEMA_ID,\n            SCHEMA_NAME,\n            TABLE_ID,\n            TABLE_NAME,\n            FILE_NAME,\n            LAST_LOAD_TIME,\n            STATUS,\n            ROW_COUNT,\n            ROW_PARSED\n        FROM SNOWFLAKE.ACCOUNT_USAGE.LOAD_HISTORY\n        WHERE CATALOG_NAME = '{}' \n        AND SCHEMA_NAME = '{}'\n        AND TABLE_NAME = '{}'\n        ORDER BY LAST_LOAD_TIME DESC\n    '''.format(\n        selected_db,\n        selected_schema,\n        selected_tb\n    )\nelse:\n    load_hist_all_query ='''\n        SELECT \n            NULL AS CATALOG_ID,\n            NULL AS CATALOG_NAME,\n            NULL AS SCHEMA_ID,\n            NULL AS SCHEMA_NAME,\n            NULL AS TABLE_ID,\n            NULL AS TABLE_NAME,\n            NULL AS FILE_NAME,\n            NULL AS LAST_LOAD_TIME,\n            NULL AS STATUS,\n            0 AS ROW_COUNT,\n            0 AS ROW_PARSED\n    '''\n\n# Convert to DataFrame\ndf_load_hist_all = session.sql(load_hist_all_query).to_pandas()\n\n# Display all load history DataFrame\nst.dataframe(df_load_hist_all, use_container_width = True)",
   "execution_count": null
  }
 ]
}